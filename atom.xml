<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[白驼山庄]]></title>
  <link href="https://chenrenyi.github.io/atom.xml" rel="self"/>
  <link href="https://chenrenyi.github.io/"/>
  <updated>2020-06-18T11:42:14+08:00</updated>
  <id>https://chenrenyi.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im">MWeb</generator>

  
  <entry>
    <title type="html"><![CDATA[回溯算法]]></title>
    <link href="https://chenrenyi.github.io/15924514980743.html"/>
    <updated>2020-06-18T11:38:18+08:00</updated>
    <id>https://chenrenyi.github.io/15924514980743.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">框架</h2>

<p>回溯问题算法框架<br/>
for 选择 in 选择列表:<br/>
    # 做选择<br/>
    将该选择从选择列表移除<br/>
    路径.add(选择)<br/>
    backtrack(路径, 选择列表)<br/>
    # 撤销选择<br/>
    路径.remove(选择)<br/>
    将该选择再加入可选列表</p>

<h2 id="toc_1">全排列问题</h2>

<pre><code class="language-java">package fighting.algorithm.backtrack;

import java.util.ArrayList;
import java.util.LinkedList;
import java.util.List;

/**
 * 全排列问题
 */
public class Sequence {

    public static int answer_num = 0;

    /**
     * 回溯
     *
     * @param numbers 用于排列的数字
     * @param track   路径
     */
    public static void backtrack(List&lt;Integer&gt; numbers, LinkedList&lt;Integer&gt; track) {
        if (numbers.size() == track.size()) {
            System.out.println(track);
            answer_num++;
            return;
        }

        for (int i : numbers) {
            // 如果该数已在路径中，忽略
            if (track.contains(i)) {
                continue;
            }
            // 做选择
            track.add(i);
            // 递归进入之后的选择
            backtrack(numbers, track);
            // 撤销选择
            track.removeLast();
        }
    }

    /**
     * 测试
     */
    public static void main(String ars[]) {
        List&lt;Integer&gt; numbers = new ArrayList&lt;&gt;();
        numbers.add(1);
        numbers.add(2);
        numbers.add(3);
        numbers.add(4);

        LinkedList&lt;Integer&gt; chooseList = new LinkedList&lt;&gt;();

        backtrack(numbers, chooseList);

        System.out.println(answer_num);
    }
}

</code></pre>

<h2 id="toc_2">N皇后问题</h2>

<pre><code class="language-java">package fighting.algorithm.backtrack;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

/**
 * N皇后问题
 */
public class Queen {

    public static final int QUEEN_NUM = 8;

    public static List&lt;List&lt;List&lt;String&gt;&gt;&gt; results = new ArrayList&lt;&gt;();

    public static void queen(List&lt;List&lt;String&gt;&gt; board, int row) {
        if (row &gt;= QUEEN_NUM) {
            List&lt;List&lt;String&gt;&gt; boardCopy = initBoard();
            Collections.copy(boardCopy, board);
            results.add(boardCopy);
            return;
        }
        for (int column = 0; column &lt; QUEEN_NUM; column++) {
            if (isValid(board, row, column)) {
                board.get(row).set(column, &quot;Q&quot;);
                queen(board, row + 1);
                board.get(row).set(column, &quot;&quot;);
            }
        }
    }

    public static boolean isValid(List&lt;List&lt;String&gt;&gt; board, int row, int column) {
        // false if q exists in the same column
        for (int i = 0; i &lt; row; i++) {
            if (board.get(i).get(column).equals(&quot;Q&quot;)) {
                return false;
            }
        }

        for (int i = row - 1, j = column - 1; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) {
            if (board.get(i).get(j).equals(&quot;Q&quot;)) {
                return false;
            }
        }

        for (int i = row - 1, j = column + 1; i &gt;= 0 &amp;&amp; j &lt; QUEEN_NUM; i--, j++) {
            if (board.get(i).get(j).equals(&quot;Q&quot;)) {
                return false;
            }
        }

        return true;
    }

    public static List&lt;List&lt;String&gt;&gt; initBoard() {
        List&lt;List&lt;String&gt;&gt; board = new ArrayList&lt;&gt;();
        for (int i = 0; i &lt; QUEEN_NUM; i++) {
            board.add(new ArrayList&lt;&gt;());
            for (int j = 0; j &lt; QUEEN_NUM; j++) {
                board.get(i).add(&quot;&quot;);
            }
        }

        return board;
    }

    public static void printBoard(List&lt;List&lt;String&gt;&gt; board) {
        for (int i = 0; i &lt; QUEEN_NUM; i++) {
            for (int j = 0; j &lt; QUEEN_NUM; j++) {
                if (board.get(i).get(j).equals(&quot;Q&quot;)) {
                    System.out.print(&quot; ● &quot;);
                } else {
                    System.out.print(&quot; ○ &quot;);
                }
            }
            System.out.println();
        }
        System.out.println();
    }

    public static void main(String args[]) {
        List&lt;List&lt;String&gt;&gt; board = initBoard();
        queen(board, 0);

        System.out.println(results.size());
    }
}

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ForkJoinPool 相关]]></title>
    <link href="https://chenrenyi.github.io/15922331141719.html"/>
    <updated>2020-06-15T22:58:34+08:00</updated>
    <id>https://chenrenyi.github.io/15922331141719.html</id>
    <content type="html"><![CDATA[
<pre><code class="language-java">package fighting.threads;

import java.util.Arrays;
import java.util.List;
import java.util.concurrent.*;

/**
 * ForkJoinPool学习
 * 不同之处：
 * 1、没有一个公共的任务队列，而是每个工作线程都有自己两个任务队列（外部和内部产生的子任务）
 * 2、目的是避免处理大量短平快任务时，对公共队列任务的争抢引发性能问题。即每个任务执行都很快，但多并发情况下公共任务队列push和pop的加锁成为了瓶颈
 *
 * 两个作用：
 * 1、分而治之，允许任务执行过程中，再次提交子任务，从而缩短时间
 * 2、工作窃取，线程池中已完成的工作线程，将主动获取所有线程队列中已提交未完成的任务或子任务
 *
 * 对应的类：
 * ForkJoinPool：线程池
 * ForkJoinPool.common：全局公用的线程池
 * ForkJoinTask：有返回值的任务
 * ForkJoinAction：没有返回值任务
 *
 * 相关类：
 * Executors.newWorkStealingPool()
 * stream.parallelStream()
 */
public class ForkJoinPoolTest {

    /**
     * 测试入口
     */
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        ForkJoinPool pool = new ForkJoinPool(10);
        ForkJoinTask&lt;Integer&gt; result = pool.submit(new CalcIntegerTask(0, 100000));
        System.out.println(result.get());
        pool.shutdown();

        // 通过executors创建线程池
        Executors.newWorkStealingPool().submit(() -&gt; System.out.println(&quot;a runnable task&quot;));

        // parallelStream（pærəlel），默认使用 ForkJoinPool.common
        List&lt;Integer&gt; numbers = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9);
        numbers.parallelStream().forEach(System.out::println);
    }

}

/**
 * 数字计算任务
 */
class CalcIntegerTask extends RecursiveTask&lt;Integer&gt; {

    private Integer start;

    private Integer end;

    public CalcIntegerTask(Integer start, Integer end) {
        this.start = start;
        this.end = end;
    }

    @Override
    protected Integer compute() {
        int sum = 0;
        if (end - start &lt;= 100) {
            // 数据量少时直接计算
            for (int i = start; i &lt;= end; i++) {
                sum += i;
            }
        } else {
            // 数据量大时，分而治之。拆分子任务提交
            int middle = (end - start) / 2 + start;
            CalcIntegerTask leftTask = new CalcIntegerTask(start, middle);
            CalcIntegerTask rightTask = new CalcIntegerTask(middle + 1, end);

            // 子任务需要调用 fork 方法
            leftTask.fork();
            rightTask.fork();

            // 使用 join 方法等待并获取值
            sum = leftTask.join() + rightTask.join();
        }

        return sum;
    }
}

</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[概念理论]]></title>
    <link href="https://chenrenyi.github.io/15922330840064.html"/>
    <updated>2020-06-15T22:58:04+08:00</updated>
    <id>https://chenrenyi.github.io/15922330840064.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">CAP</h2>

<p>分布式系统的3个指标，这3个指标只能同时满足两个</p>

<ul>
<li>Consistency：一致性</li>
<li>Availability：可用性</li>
<li>Partition tolerance：分区容错性</li>
</ul>

<h3 id="toc_1">Consistency：一致性</h3>

<p><strong>概念</strong></p>

<p>写之后进行读，能读到值即满足一致性</p>

<p><strong>主要问题</strong></p>

<p>写入集群中A机器，读B机器。B机器数据未同步前数据不是最新的。</p>

<p><strong>解决办法</strong></p>

<p>写入到集群中A机器时，在自身保存完毕并确保同步到B机器后，再返回写入成功。因此写入有延时。</p>

<h3 id="toc_2">Availability：可用性</h3>

<p><strong>概念</strong></p>

<p>服务收到请求后，要立即回答</p>

<p><strong>主要问题</strong></p>

<p>与上述一致性有冲突，网络故障时也有影响</p>

<h3 id="toc_3">Partition tolerance：分区容错性</h3>

<p><strong>概念</strong></p>

<p>集群中各个区之间是否允许有网络故障问题</p>

<p><strong>主要问题</strong></p>

<p>分布式系统必然肯定要允许，所以p必须保证。从而 c、a 只能选一</p>

<h3 id="toc_4">可用性与一致性矛盾</h3>

<pre><code class="language-text">一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。

如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。

如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。

综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。
</code></pre>

<h2 id="toc_5">RPC</h2>

<p>构成：</p>

<ul>
<li>RPC协议：基于http，或者基于tcp自己定义协议</li>
<li>序列化机制：JSON、xml、java自带的，或者开源第三方的。发送参数、返回结果对象</li>
<li>代理：java的动态代理，切入转发逻辑</li>
</ul>

<h3 id="toc_6">序列化协议</h3>

<ul>
<li>java原生（ObjectInputStream)
<ul>
<li>不能跨平台</li>
<li>体积大，性能差</li>
</ul></li>
<li>protobuf（potike)
<ul>
<li>谷歌出品，本质是一种结构化数据描述文件</li>
</ul></li>
<li>Thrift(θrɪft)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[spring cloud 系列]]></title>
    <link href="https://chenrenyi.github.io/15922330508180.html"/>
    <updated>2020-06-15T22:57:30+08:00</updated>
    <id>https://chenrenyi.github.io/15922330508180.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">服务注册</h2>

<p>提供服务的注册与查询功能</p>

<h3 id="toc_1">Eureka</h3>

<p>保证cap中的ap，即可用性。<br/>
服务注册相对要快，因为不需要等注册信息replicate到其他节点，也不保证注册信息是否replicate成功<br/>
当数据出现不一致时，虽然A, B上的注册信息不完全相同，但每个Eureka节点依然能够正常对外提供服务，这会出现查询服务信息时如果请求A查不到，但请求B就能查到。如此保证了可用性但牺牲了一致性</p>

<h3 id="toc_2">Consule</h3>

<p>保证cap中的cp，即强一致性。<br/>
服务注册相比Eureka会稍慢一些。因为Consul的raft协议要求必须过半数的节点都写入成功才认为注册成功<br/>
Leader挂掉时，重新选举期间整个consul不可用。保证了强一致性但牺牲了可用性。</p>

<h2 id="toc_3">网关 - Api Gateway</h2>

<h3 id="toc_4">介绍</h3>

<p>网关：路由分发和过滤</p>

<ul>
<li>作为代理，如nginx一般转发请求到后端服务</li>
<li>配置服务注册中心，根据服务名自动转发</li>
<li>统一请求入口，进行公共处理，如：
<ul>
<li>身份认证</li>
<li>日志记录</li>
<li>配合限流库：hystrix，熔断限流降级依赖隔离等</li>
<li>配合负载均衡库：ribbon，流量负载均衡</li>
</ul></li>
</ul>

<h3 id="toc_5">zuul</h3>

<p><em>路由转发</em></p>

<blockquote>
<p>与服务注册中心配置时不需要配置</p>
</blockquote>

<pre><code class="language-text">zuul:
    routes:
        bms-biz:
            path: /api/bms/biz/**
            sensitiveHeaders: Content-Length
            url: http://bms-biz.dsg.cfpamf.com
</code></pre>

<p><em>过滤</em></p>

<pre><code class="language-text">preFilter  # 转发前拦截处理
routeFilter # 实际路由
postFilter  # 转发后拦截处理
</code></pre>

<h3 id="toc_6">spring cloud gateway</h3>

<p>同上</p>

<h2 id="toc_7">网络相关</h2>

<h3 id="toc_8">feign</h3>

<p>http调用客户端，通过注解调用接口<br/>
本质是 ribbon + hystrix</p>

<h3 id="toc_9">ribbon</h3>

<p>负载均衡，重试</p>

<h3 id="toc_10">Hystrix</h3>

<blockquote>
<p>[hIst&#39;rIks](嗨斯捶克斯）</p>
</blockquote>

<p>客户端容错保护，特性有服务降级、服务熔断、请求缓存、请求合并、依赖隔离</p>

<p><strong>断路器</strong></p>

<pre><code class="language-text">@HystrixCommand(fallbackMethod = &quot;processHystrix_Get&quot;)
</code></pre>

<p>达到一定条件时，不再执行原方法，而改为执行 fallback 方法</p>

<h2 id="toc_11">配置中心</h2>

<h3 id="toc_12">spring cloud config</h3>

<p>提供配置信息</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker笔记]]></title>
    <link href="https://chenrenyi.github.io/15916082982624.html"/>
    <updated>2020-06-08T17:24:58+08:00</updated>
    <id>https://chenrenyi.github.io/15916082982624.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Hello World!</h2>

<p>下载一个镜像并运行</p>

<pre><code class="language-text">docker image pull library/hello-world

docker image ls 

docker run hello-world
</code></pre>

<h2 id="toc_1">基本操作</h2>

<p>镜像相关</p>

<pre><code class="language-text">docker image help   # 帮助
docker image ls     # 查看
docker image rm     # 删除
</code></pre>
<br>
<p>容器相关</p>

<blockquote>
<p>容器有可能在运行完毕后自动结束，也可能是常驻服务，后者可用kill命令杀掉</p>
</blockquote>

<pre><code class="language-text">docker container help   # 帮助
docker container ls     # 查看
docker container ls --all     # 查看包括已终止的所有容器

docker container run    # 新建容器
docker container start  # 启动
docker container stop   # 停止，比 kill 更柔和
docker container exec -it  # 进入一个正在运行的容器
docker container cp  [containID]:[/path/to/file] .    # 复制文件

docker container logs [containerID] # 查看容器日志输出

docker container rm     # 杀掉容器
docker container rm     # 删除容器文件
</code></pre>

<h2 id="toc_2">Dockfile</h2>

<blockquote>
<p>Dockfile用于配置生成image，即如果要自定义image需要使用它</p>
</blockquote>

<p>示例：打包一个 npm 前端网站</p>
<br>
<p>1、创建 .dockerignore 文件，即打包时需要排除的文件</p>

<pre><code class="language-text">.git
node_modules
npm-debug.log
</code></pre>
<br>
<p>2、编写Dockerfile</p>

<pre><code class="language-text">FROM node:8.4   # 在该官方包的基础上进行
COPY . /app     # 将目录 . 的内容复制进镜像的 /app 目录中
WORKDIR /app    # 以 /app 目录作为工作所在目录
RUN npm install --registry=https://registry.npm.taobao.org # 运行 npm 命令，该阶段产生的文件将被打包进 image 文件中
EXPOSE 3000     # 暴露 3000 端口

CMD npm run dev # 启动命令。RUN 编译镜像文件时运行，结果会打包进去。而 CMD 为容器启动时运行，只有一个
</code></pre>
<br>
<p>3、编译生成 image 文件</p>

<pre><code class="language-bash">docker image build -t front-demo .      # -t 指定名字和版本号
docker image ls                         # 查看
</code></pre>
<br>
<p>4、运行</p>

<pre><code class="language-bash">docker container run -p 8000:3000 -it front-demo /bin/bash # 交互模式运行并映射端口，同时启动 /bin/bash，会覆盖 CMD 命令
docker container run -rm -p 8000:3000 -it front-demo /bin/bash # 运行完毕后即删除容器文件
</code></pre>

<h2 id="toc_3">真实案例：生成网站</h2>

<h3 id="toc_4">mysql容器</h3>

<pre><code class="language-bash">docker container run --name wordpressdb --env MYSQL_ROOT_PASSWORD=123456 --env MYSQL_DATABASE=wordpress -d mysql:5.7
</code></pre>

<h3 id="toc_5">单独php容器</h3>

<p>编写Dockerfile</p>

<pre><code class="language-dockerfile"># dockerfile
FROM php:5.6-apache
RUN docker-php-ext-install mysqli
CMD apache2-foreground
</code></pre>

<p>制作镜像</p>

<pre><code class="language-bash">docker image build -t php-demo:1.0 .
</code></pre>

<p>运行容器</p>

<pre><code class="language-bash">docker run --name php-demo --rm -p 7000:80 --volume &quot;$PWD&quot;:/var/www/html --link wordpressdb:mysql php-demo:1.0
</code></pre>

<h2 id="toc_6">Docker compose</h2>

<p>编写 docker-compose.yml</p>

<pre><code class="language-yaml">mysql:
  image: mysql:5.7
  environment:
    MYSQL_ROOT_PASSWORD: 123456
    MYSQL_DATABASE: wordpress

web:
  image: php-demo:1.0
  links:
    - mysql
  ports:
    - &quot;7000:80&quot;
  working_dir: /var/www/html
  volumes:
    - /tmp/docker-demo/wordpress:/var/www/html
</code></pre>

<p>运行</p>

<pre><code class="language-text">docker-compose up
</code></pre>

<h2 id="toc_7">容器原理</h2>

<h3 id="toc_8">Namespace</h3>

<p>Linux的命名空间技术，用于实现进程、文件、网络等资源的隔离</p>

<h3 id="toc_9">Control Groups CGroup</h3>

<p>控制组，用于限制容器的 cpu、内存、网络等使用</p>

<h3 id="toc_10">UnionFS</h3>

<p>联合挂载技术，Dockfile的每一条文件变更命令都会产生一个 layer 层，即文件读写层。</p>

<p>用于实现 docker 的镜像容器文件等的分层技术</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zuul 网关记录请求全生命周期日志]]></title>
    <link href="https://chenrenyi.github.io/15913291441737.html"/>
    <updated>2020-06-05T11:52:24+08:00</updated>
    <id>https://chenrenyi.github.io/15913291441737.html</id>
    <content type="html"><![CDATA[
<p>微服务架构中网关是所有对外提供服务的入口，一个常见的需求是对每个请求记录详细日志，包括url、method、header、request body、response status、response body等，方便问题排查而不用每个内部服务再做一套日志了。</p>

<p>以下为zuul框架搭建的网关记录全链路日志的方法。</p>

<h3 id="toc_0">思路介绍</h3>

<p>zuul有个处理代理请求工具类<code>ProxyRequestHelper</code>，用在关键的请求转发处理上。并且官方带一个子类<code>TraceProxyRequestHelper</code>，其中记录了不少debug信息和一些关键的钩子方法，包括我们需要的请求数据、转发模式等。因此继承这个子类，重写一些方法并把需要的信息，导出来存成日志即ok。</p>

<h3 id="toc_1">步骤源码</h3>

<p>1、如上面思路介绍，新建子类并继承<code>TraceProxyRequestHelper</code>，具体为什么这么改可以参见注释</p>

<pre><code class="language-java">import com.netflix.zuul.context.RequestContext;
import com.netflix.zuul.util.HTTPRequestUtils;
import lombok.extern.slf4j.Slf4j;
import org.springframework.cloud.netflix.zuul.filters.TraceProxyRequestHelper;
import org.springframework.http.HttpHeaders;
import org.springframework.util.CollectionUtils;
import org.springframework.util.MultiValueMap;
import org.springframework.util.StreamUtils;
import org.springframework.util.StringUtils;

import java.io.ByteArrayInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.nio.charset.StandardCharsets;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import static org.springframework.http.HttpHeaders.CONTENT_ENCODING;
import static org.springframework.http.HttpHeaders.CONTENT_LENGTH;

/**
 * 继承zuul的实现，添加调试日志
 */
@Slf4j
public class MyTraceProxyRequestHelper extends TraceProxyRequestHelper {

    public static final String REQUEST_TRACE_DATA_KEY = &quot;MyRequestTraceData&quot;;

    public static final String RESPONSE_TRACE_DATA_KEY = &quot;MyResponseTraceData&quot;;

    /**
     * 在这里保存 request 的相关信息供之后导出来
     */
    @Override
    public Map&lt;String, Object&gt; debug(String verb, String uri, MultiValueMap&lt;String, String&gt; headers, MultiValueMap&lt;String, String&gt; params, InputStream requestEntity) throws IOException {
        Map&lt;String, Object&gt; result = super.debug(verb, uri, headers, params, requestEntity);
        RequestContext.getCurrentContext().getRequest().setAttribute(REQUEST_TRACE_DATA_KEY, result);
        return result;
    }

    /**
     * 在这里保存 response 的相关信息供之后导出来
     * 大部分代码复制自父类
     */
    @Override
    public void setResponse(int status, InputStream entity, MultiValueMap&lt;String, String&gt; headers) throws IOException {
        RequestContext context = RequestContext.getCurrentContext();
        context.setResponseStatusCode(status);

        // 记录response日志
        debugResponse(status, entity, headers);

        HttpHeaders httpHeaders = new HttpHeaders();
        for (Map.Entry&lt;String, List&lt;String&gt;&gt; header : headers.entrySet()) {
            List&lt;String&gt; values = header.getValue();
            for (String value : values) {
                httpHeaders.add(header.getKey(), value);
            }
        }
        boolean isOriginResponseGzipped = false;
        if (httpHeaders.containsKey(CONTENT_ENCODING)) {
            List&lt;String&gt; collection = httpHeaders.get(CONTENT_ENCODING);
            for (String header : collection) {
                if (HTTPRequestUtils.getInstance().isGzipped(header)) {
                    isOriginResponseGzipped = true;
                    break;
                }
            }
        }
        context.setResponseGZipped(isOriginResponseGzipped);

        for (Map.Entry&lt;String, List&lt;String&gt;&gt; header : headers.entrySet()) {
            String name = header.getKey();
            for (String value : header.getValue()) {
                context.addOriginResponseHeader(name, value);
                if (name.equalsIgnoreCase(CONTENT_LENGTH)) {
                    context.setOriginContentLength(value);
                }
                if (isIncludedHeader(name)) {
                    context.addZuulResponseHeader(name, value);
                }
            }
        }
    }

    /**
     * 新增的辅助方法，只有json等返回类型时才记录response日志
     * 判断response content-type是否是json、xml等正常接口返回类型
     */
    private boolean matchesMimeType(MultiValueMap&lt;String, String&gt; headers) {
        if (CollectionUtils.isEmpty(headers)) {
            return false;
        }
        String contentType = null;
        for (Map.Entry entry : headers.entrySet()) {
            if (entry.getKey().toString().equalsIgnoreCase(HttpHeaders.CONTENT_TYPE)) {
                List list = (ArrayList) entry.getValue();
                contentType = (String) list.get(0);
                break;
            }
        }
        if (StringUtils.isEmpty(contentType)) {
            return false;
        }
        String[] mimeTypes = new String[]{&quot;text/html&quot;, &quot;text/xml&quot;, &quot;application/xml&quot;, &quot;application/json&quot;};
        for (String mimeType : mimeTypes) {
            if (contentType.contains(mimeType)) {
                return true;
            }
        }
        return false;
    }

    /**
     * 辅助方法
     * 实际记录response返回日志
     */
    private void debugResponse(int status, InputStream entity, MultiValueMap&lt;String, String&gt; headers) throws IOException {
        if (entity == null) {
            return;
        }

        // 非需要解析的content-type，不做处理
        RequestContext context = RequestContext.getCurrentContext();
        if (!matchesMimeType(headers)) {
            context.setResponseDataStream(entity);
            return;
        }

        byte[] entityByteArray = StreamUtils.copyToByteArray(entity);
        InputStream wrappedEntity = new ByteArrayInputStream(entityByteArray);

        //记录response
        char[] buffer = new char[4096];
        int count;
        boolean isSmallBody = true;
        try (InputStreamReader input = new InputStreamReader(wrappedEntity, StandardCharsets.UTF_8)) {
            count = input.read(buffer, 0, buffer.length);
            if (input.read() != -1) {
                isSmallBody = false;
            }
        }
        if (count &gt; 0) {
            String resp = new String(buffer).substring(0, count);
            context.getRequest().setAttribute(RESPONSE_TRACE_DATA_KEY, (isSmallBody ? resp : resp + &quot;&lt;truncated&gt;&quot;));
        }
        wrappedEntity.reset();
        context.setResponseDataStream(wrappedEntity);
    }

}
</code></pre>
<br>
<p>2、启用新建好的子类。新建个配置项，将自定义的子类，设置为<code>proxyRequestHelper</code>这个<code>bean</code>的默认实现(<code>@Primary</code>)</p>

<pre><code class="language-java">import org.springframework.boot.actuate.trace.InMemoryTraceRepository;
import org.springframework.cloud.netflix.zuul.ZuulProxyAutoConfiguration;
import org.springframework.cloud.netflix.zuul.filters.ProxyRequestHelper;
import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;

@Configuration
public class MyZuulAutoConfiguration extends ZuulProxyAutoConfiguration {
    @Bean
    @Primary
    public ProxyRequestHelper proxyRequestHelper(ZuulProperties zuulProperties) {
        MyTraceProxyRequestHelper helper = new MyTraceProxyRequestHelper();
        helper.setTraces(new InMemoryTraceRepository());
        helper.setIgnoredHeaders(zuulProperties.getIgnoredHeaders());
        helper.setTraceRequestBody(zuulProperties.isTraceRequestBody());
        return helper;
    }
}

</code></pre>
<br>
<p>3、获取日志内容并实际写入日志。这儿可以建一个spring的请求拦截器<code>OncePerRequestFilter</code>，记录请求耗时并在处理完毕后写入日志。</p>

<pre><code class="language-java">import lombok.extern.slf4j.Slf4j;
import org.apache.commons.lang.StringUtils;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.filter.OncePerRequestFilter;

import javax.servlet.FilterChain;
import javax.servlet.ServletException;
import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;
import java.io.IOException;
import java.util.LinkedHashMap;
import java.util.Map;

/**
 * 添加调试日志信息
 */
@Configuration
@Slf4j
public class LogFilter extends OncePerRequestFilter {

    public static final String REQUEST_BEGIN_TIME = &quot;REQUEST_BEGIN_TIME&quot;;

    @Override
    protected void doFilterInternal(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, FilterChain filterChain) throws ServletException, IOException {
        httpServletRequest.setAttribute(REQUEST_BEGIN_TIME, System.currentTimeMillis());
        filterChain.doFilter(httpServletRequest, httpServletResponse);
        traceLog(httpServletRequest);
    }

    /**
     * 记录日志
     */
    private void traceLog(HttpServletRequest request) {
        Long begin = (Long) request.getAttribute(REQUEST_BEGIN_TIME);
        if (begin == null || begin == 0L) {
            begin = System.currentTimeMillis();
        }

        Map&lt;String, Object&gt; logData = new LinkedHashMap&lt;&gt;();
        Map&lt;String, Object&gt; requestMap = (Map&lt;String, Object&gt;) request.getAttribute(REQUEST_TRACE_DATA_KEY);
        logData.put(&quot;url&quot;, request.getRequestURL());
        logData.put(&quot;uri&quot;, request.getRequestURI());
        logData.put(&quot;timeCost&quot;, System.currentTimeMillis() - begin);
        if (requestMap != null) {
            logData.putAll(requestMap);
        }
        logData.put(&quot;responseBody&quot;, StringUtils.abbreviate(String.valueOf(request.getAttribute(RESPONSE_TRACE_DATA_KEY)), 128));

        log.info(&quot;{}&quot;, logData);
    }
}

</code></pre>
<br>
<p><strong>ok了，至此大功告成！</strong></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[iText 生僻字显示设置与汉字数字化]]></title>
    <link href="https://chenrenyi.github.io/15827936185226.html"/>
    <updated>2020-02-27T16:53:38+08:00</updated>
    <id>https://chenrenyi.github.io/15827936185226.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">问题描述</h2>

<p>iText 生成的 pdf，无法显示某些生僻字，比如【㙓】、【𠅤】。在遇到生僻字时不会显示成方块，而是直接不显示。<br/>
<span id="more"></span><!-- more --></p>

<h2 id="toc_1">原来生成 pdf 的过程</h2>

<p>1、用 FreeMarker 模板引擎生成 html，html 里面的 css 指定了字体文件<br/>
<a href="media/15827936185226/docs.css">docs</a></p>

<pre><code class="language-css">body {font-family: SimSun}
</code></pre>

<p>2、添加 SimSun 字体文件</p>

<pre><code class="language-java">new ITextRenderer().getFontResolver().addFont(&quot;SimSun.ttf&quot;)
</code></pre>

<p>3、用 iText 框架将 html 转化成 pdf 文件</p>

<pre><code class="language-java">renderer.setDocumentFromString(content, storagePath);
</code></pre>

<h2 id="toc_2">原因分析</h2>

<p>原因简单说来，就是 SimSun.ttf（中易宋体，也是 windows 系统默认字体）中未收录某些生僻字，所以生成的 pdf 中显示不出来。</p>

<p>至于为啥不收录以及对应的解决办法，需要先了解下计算机是如何显示汉字的。或者也可以直接跳过看最终解决方案，再回过头看原理。</p>

<h2 id="toc_3">汉字的数字化历史</h2>

<h3 id="toc_4">汉字有多少个</h3>

<p>生活中的情况：我国义务教育阶段要求识字 3500 个左右，2013 年国务院发布的《通用规范汉字表》，收录汉字 8105 个，分为三级，其中一级字为常用字共 3500个，二级字 3000 个，三级字 1605 个。</p>

<p>书本中的情况：东汉的《说文解字》收字 9353 个，清朝《康熙字典》收字 47,035 个，当代的《汉语大字典》（2010 年版) 收字 60,370 个。 1994 年中华书局、中国友谊出版公司出版的《中华字海》收字 85,568 个。</p>

<p>据估算总汉字约 10 万个，具体数字无人清楚。</p>

<h3 id="toc_5">把汉字放进计算机，汉字编码历史</h3>

<p>想用计算机传输存储文字，必然要有编码方案。但汉字实在太多，所以编码方案是演进型的，初期只收录的字数很少，后面才慢慢扩充。</p>

<h4 id="toc_6">国标：</h4>

<p>1981 年：发布 GB2312—1980，收录汉字 6763 个和非汉字图形字符 682 个<br/>
1995 年：发布 GBK，收录 21886 个汉字和图形符号<br/>
2001 年：发布 GB18030，共收录汉字 70,244 个</p>

<h4 id="toc_7">unicode：</h4>

<p>unicode 的目的是国际通行，而国际上汉字使用除中国外，还有日韩。因此为了统一汉字编码，有了中日韩统一表意文字 (即 CJK，各国英文名首字母)。为啥要讲 unicode 呢，因为编程语言对它的支持好啊。</p>

<p>从1991年到2018年，先是发布了第一版，后来陆续增加了扩展表 A、B、C、D、E、F区</p>

<h3 id="toc_8">把汉字显示出来，字体文件</h3>

<p>有了编码方案，还要有字体文件，知道如何把汉字画出来。因为汉字数量太多，编码方案是演进型的，所以字体文件也只提供了一部分汉字。</p>

<p>常用字体文件格式：<br/>
ttf：最常用的，微软和苹果合推的<br/>
ttc：本质是多个ttf的集合<br/>
otf：是ttf的升级版，测试发现iText框架貌似不支持</p>

<p>我从网上下载的许多号称超大字符集的字体文件，里面都是分为好几个 ttf 文件的。有两个原因，一是常用字已经有字体文件了，因此只需要再提供一份生僻字的文件即可。二是有ttf格式有数量上限，没法放下全部的字。</p>

<h2 id="toc_9">字体显示的 fallback 机制</h2>

<p>上面解释了为什么单个字体文件没包含所有字，但实际上的情况是，有些字在系统上和浏览器中能看到，比如举例中的【𠅤】，而 pdf 中却不显示呢？</p>

<h3 id="toc_10">操作系统/浏览器是怎么处理字体缺失的？</h3>

<p>fallback，即回退机制：如果指定用字体 A 来显示某字符 x，但该字体并不支持这个字符（甚至该字体当前不可用），排版引擎通常不会直接放弃，它会根据一个预先记好的列表来尝试寻找能显示字符 x 的字体，如果找到字体 B 能行，那就用字体 B 来显示字符 x。字体 B 就是当前这个情况的 fallback。</p>

<h3 id="toc_11">生成 pdf 时为啥不支持 fallback？</h3>

<p>pdf：主要用于打印和阅读，而非编辑。有一个特点是：它可以将文字、字型、格式、颜色及独立于设备和分辨率的图形图像等封装在一个文件中，个人理解就是跟图片一样，封装了所有的显示效果，所以无论在什么平台打开，排版效果都是一样的。</p>

<p>所以它是一个独立的不依赖于平台的格式，个人猜测这也就是为什么它不支持操作系统的fallback机制。</p>

<h2 id="toc_12">解决方案</h2>

<p>知道了单个字体不包含所有文件，pdf 也不支持 fallback 机制后，解决方案如下：</p>

<p>1、引入最新版 SimSun.ttf，SimSun-extB.ttf 两个文件，我从 win10 最新版中导入的，经测试前者包含 cjk 与扩展 A 区的字体，后者包含其它区的字体。</p>

<p>2、iText 框架添加上面两个字体，参见 2.2</p>

<p>3、html 中指定默认字体为 SimSun，参见 2.1</p>

<p>4、遍历 html 内容，扫描出 B 区及以后的字体，手动指定字体格式 SimSun-ExtB。代码如下：</p>

<pre><code class="language-java">    /**
     * 扫描待转化成pdf的html内容，为生僻字指定生僻字体，解决生僻字不显示的问题
     */
    private String addFontFamilyForUncommonWords(String string) {
        int[] stringUnicodes = StringUtils.toCodePoints(string);
        StringBuffer resultString = new StringBuffer();

        for (int charUnicode : stringUnicodes) {
            // 中易宋体(simsun)含有常规字符及cjk扩展表A的内容，中易宋体扩展版(simsun-extb)有cjk其它扩展表区内容
            Character.UnicodeBlock ub = Character.UnicodeBlock.of(charUnicode);
            if (ub == Character.UnicodeBlock.CJK_UNIFIED_IDEOGRAPHS_EXTENSION_B
                    || ub == Character.UnicodeBlock.CJK_UNIFIED_IDEOGRAPHS_EXTENSION_C
                    || ub == Character.UnicodeBlock.CJK_UNIFIED_IDEOGRAPHS_EXTENSION_D) {
                resultString.append(&quot;&lt;font style=&#39;font-family: SimSun-ExtB&#39;&gt;&quot;);
                resultString.append(Character.toChars(charUnicode));
                resultString.append(&quot;&lt;/font&gt;&quot;);
            } else {
                resultString.append(Character.toChars(charUnicode));
            }
        }

        return resultString.toString();
    }
</code></pre>

<h2 id="toc_13">其它方案</h2>

<h3 id="toc_14">1、换框架，不用 iText。</h3>

<p>网上搜索其它 pdf 框架结果很少，因此未作尝试</p>

<h3 id="toc_15">2、css 中指定多个字体解决</h3>

<p>经测试，在 css 的 font-family 中指定多个字体，生成 pdf 时只按顺序使用第一个存在的字体，即常用字体在前只显示常用字，生僻字体在前只显示生僻字。原因相关知识中有写，生成 pdf 时不支持 fallback 机制。</p>

<h3 id="toc_16">3、默认字体指定为一个超全超大的字体文件</h3>

<p>相关知识中有介绍，ttf 格式有字形上限，收录字形想全必须存在多个文件。同时 iText 不支持 otf 格式，支持 ttc 格式但必须指定序号，即用 ttc 中包含的哪一个 ttf，因此不行。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一篇文章]]></title>
    <link href="https://chenrenyi.github.io/15818551802185.html"/>
    <updated>2020-02-16T20:13:00+08:00</updated>
    <id>https://chenrenyi.github.io/15818551802185.html</id>
    <content type="html"><![CDATA[
<p>因新冠肺炎疫情呆在家里的第 26 天，闲来无事第 n 次搭建博客，写下同样第 n 次的开篇文章。</p>

<span id="more"></span><!-- more -->

<p>这一次用的 Mweb（页脚权限声明那有官网链接），Mac 上一个 Markdown 写作软件，自带静态博客创建和发布功能，支持自定义发布脚本。日常在编辑器书写，完成后一键发布即可。</p>

<p>当然了，这软件是收费的。国内开发者，做得挺用心。比如我个人很喜欢的一个小功能是，“在中文和半角的英文、数字之间插入空格”，Github 上也有开源实现，称呼这种空格为盘古白，各编程语言版本都有。与 Word 和手机微信的聊天框显示效果类似。其实代码实现并不复杂，但能从中一窥作者对排版和用户体验的细节追求。</p>

<p>有缘看到的兄弟可以试试。如果软件作者看到了，记得给我打钱啊😆</p>

]]></content>
  </entry>
  
</feed>
